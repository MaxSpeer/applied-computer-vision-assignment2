{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d504a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageShow\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50eb0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_colab() -> bool:\n",
    "    try:\n",
    "        import google.colab  # noqa: F401\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "if in_colab():\n",
    "    !git clone https://github.com/MaxSpeer/applied-computer-vision-assignment2.git\n",
    "    %cd applied-computer-vision-assignment2\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install -e .\n",
    "else:\n",
    "    from pathlib import Path\n",
    "    import sys\n",
    "    project_root = Path(\"..\").resolve()\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9da7ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f3581c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "VALID_BATCHES = 10\n",
    "N = 9999\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),  # Scales data into [0,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3da5535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading config file fiftyone.yml from maxspeer/assessment2_spheres_and_cube_2k_2\n",
      "Loading dataset\n",
      "Importing samples...\n",
      " 100% |███████████████| 6000/6000 [52.8ms elapsed, 0s remaining, 113.6K samples/s]  \n",
      "Session launched. Run `session.show()` to open the App in a cell output.\n",
      "http://localhost:5151/\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "\n",
    "#fo.delete_dataset(\"multimodal-shapes-subset\")\n",
    "dataset_hf = load_from_hub(\"maxspeer/assessment2_spheres_and_cube_2k_2\",\n",
    "                         name=\"multimodal-shapes-subset\",\n",
    "                         num_workers=4,\n",
    "                         batch_size=500,\n",
    "                        #max_samples=3000,\n",
    "                           overwrite=True\n",
    "                        )\n",
    "\n",
    "# fiftyone session\n",
    "session = fo.launch_app(dataset_hf, auto=False)\n",
    "print(session.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "79bcebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import MultimodalDataset\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),  # Scales data into [0,1] TODO correct non deprecated version\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = MultimodalDataset(dataset_hf,\"train\",img_transforms)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "val_dataset = MultimodalDataset(dataset_hf,\"val\",img_transforms)\n",
    "valid_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30e4c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "CILP_EMB_SIZE = 200\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, in_ch, emb_size=CILP_EMB_SIZE):\n",
    "        super().__init__()\n",
    "        kernel_size = 3\n",
    "        stride = 1\n",
    "        padding = 1\n",
    "\n",
    "        # Convolution\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 50, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(50, 100, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(100, 200, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(200, 200, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Embeddings\n",
    "        self.dense_emb = nn.Sequential(\n",
    "            nn.Linear(200 * 4 * 4, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, emb_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.conv(x)\n",
    "        emb = self.dense_emb(conv)\n",
    "        return F.normalize(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d599ddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_embedder = Embedder(4).to(device)\n",
    "lidar_embedder = Embedder(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b5bbfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastivePretraining(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.img_embedder = img_embedder\n",
    "        self.lidar_embedder = lidar_embedder\n",
    "        self.cos = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "    def forward(self, rgb_imgs, lidar_depths):\n",
    "        img_emb = self.img_embedder(rgb_imgs)\n",
    "        lidar_emb = self.lidar_embedder(lidar_depths)\n",
    "\n",
    "        repeated_img_emb = img_emb.repeat_interleave(len(img_emb), dim=0)\n",
    "        repeated_lidar_emb = lidar_emb.repeat(len(lidar_emb), 1)\n",
    "\n",
    "        similarity = self.cos(repeated_img_emb, repeated_lidar_emb)\n",
    "        similarity = torch.unflatten(similarity, 0, (BATCH_SIZE, BATCH_SIZE))\n",
    "        similarity = (similarity + 1) / 2\n",
    "\n",
    "        #logits_per_img = similarity\n",
    "        #logits_per_lidar = similarity.T\n",
    "        \n",
    "        logits_per_img = similarity / 0.07\n",
    "        logits_per_lidar = logits_per_img.T\n",
    "\n",
    "\n",
    "        return logits_per_img, logits_per_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9d83e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ContrastivePretraining(nn.Module):\n",
    "#     def __init__(self, img_embedder, lidar_embedder, init_temp=0.07):\n",
    "#         super().__init__()\n",
    "#         self.img_embedder = img_embedder\n",
    "#         self.lidar_embedder = lidar_embedder\n",
    "#         self.logit_scale = nn.Parameter(torch.tensor(np.log(1/init_temp), dtype=torch.float32))\n",
    "\n",
    "#     def forward(self, rgb_imgs, lidar_depths):\n",
    "#         img_emb = self.img_embedder(rgb_imgs)          # [B, D], normalized\n",
    "#         lidar_emb = self.lidar_embedder(lidar_depths)  # [B, D], normalized\n",
    "\n",
    "#         scale = self.logit_scale.exp().clamp(1, 100)\n",
    "#         logits = scale * (img_emb @ lidar_emb.T)       # [B, B]\n",
    "#         return logits, logits.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0fa168cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CILP_model = ContrastivePretraining().to(device)\n",
    "optimizer = Adam(CILP_model.parameters(), lr=0.0001)\n",
    "loss_img = nn.CrossEntropyLoss()\n",
    "loss_lidar = nn.CrossEntropyLoss()\n",
    "ground_truth = torch.arange(BATCH_SIZE, dtype=torch.long).to(device)\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3afbe756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CILP_loss(batch):\n",
    "    rbg_img = batch[0].to(device)\n",
    "    lidar_depth = batch[2].to(device)\n",
    "    class_idx = batch[3].to(device)\n",
    "\n",
    "    logits_per_img, logits_per_lidar = CILP_model(rbg_img, lidar_depth)\n",
    "\n",
    "    total_loss = (loss_img(logits_per_img, ground_truth) +\n",
    "        loss_lidar(logits_per_lidar, ground_truth)\n",
    "    ) / 2\n",
    "\n",
    "    return total_loss, logits_per_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03174b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/maximilian/code/assessment2/notebooks/wandb/run-20260131_214350-7rbfkm1b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/maximilian-speer-hasso-plattner-institut/assessment2_notebook4/runs/7rbfkm1b' target=\"_blank\">CILP_Pretraining_rgb/lidar_bs32_ep10</a></strong> to <a href='https://wandb.ai/maximilian-speer-hasso-plattner-institut/assessment2_notebook4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/maximilian-speer-hasso-plattner-institut/assessment2_notebook4' target=\"_blank\">https://wandb.ai/maximilian-speer-hasso-plattner-institut/assessment2_notebook4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/maximilian-speer-hasso-plattner-institut/assessment2_notebook4/runs/7rbfkm1b' target=\"_blank\">https://wandb.ai/maximilian-speer-hasso-plattner-institut/assessment2_notebook4/runs/7rbfkm1b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb.init fertig\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch 0 | Train loss: 0.784947\n",
      "Epoch 0 | Valid loss: 0.807195\n",
      "New best at epoch 0: 0.807195\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch 1 | Train loss: 0.771363\n",
      "Epoch 1 | Valid loss: 0.798061\n",
      "New best at epoch 1: 0.798061\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch 2 | Train loss: 0.775447\n",
      "Epoch 2 | Valid loss: 0.780357\n",
      "New best at epoch 2: 0.780357\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch 3 | Train loss: 0.801186\n",
      "Epoch 3 | Valid loss: 0.803570\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import wandb\n",
    "from src.training import getWandbRun\n",
    "\n",
    "# Make sure CILP is trainable (in case you froze it during projector training)\n",
    "for p in CILP_model.parameters():\n",
    "    p.requires_grad = True\n",
    "CILP_model.train()\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_epoch = -1\n",
    "best_ckpt = None\n",
    "\n",
    "batch_size = BATCH_SIZE\n",
    "epochs = 10\n",
    "\n",
    "with getWandbRun(\n",
    "    \"CILP_Pretraining\",\n",
    "    \"rgb/lidar\",\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    project_name=\"assessment2_notebook4\"\n",
    ") as run:\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ---------------- train ----------------\n",
    "        CILP_model.train()\n",
    "        train_loss = 0.0\n",
    "        n_train = 0\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            loss, logits_per_img = get_CILP_loss(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            n_train += 1\n",
    "\n",
    "        train_avg = train_loss / max(n_train, 1)\n",
    "        print(f\"Epoch {epoch} | Train loss: {train_avg:.6f}\")\n",
    "\n",
    "        # ---------------- valid ----------------\n",
    "        CILP_model.eval()\n",
    "        valid_loss = 0.0\n",
    "        n_val = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_dataloader:\n",
    "                loss, logits_per_img = get_CILP_loss(batch)\n",
    "                valid_loss += loss.item()\n",
    "                n_val += 1\n",
    "\n",
    "        val_avg = valid_loss / max(n_val, 1)\n",
    "        print(f\"Epoch {epoch} | Valid loss: {val_avg:.6f}\")\n",
    "\n",
    "        # Log to W&B\n",
    "        run.log(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_avg,\n",
    "                \"valid_loss\": val_avg,\n",
    "                \"learning_rate\": optimizer.param_groups[0][\"lr\"],\n",
    "            },\n",
    "            step=epoch,\n",
    "        )\n",
    "\n",
    "        # Track best checkpoint (CPU snapshot to avoid GPU memory growth)\n",
    "        if val_avg < best_val:\n",
    "            best_val = val_avg\n",
    "            best_epoch = epoch\n",
    "            best_ckpt = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_val_loss\": best_val,\n",
    "                \"model_state_dict\": {k: v.detach().cpu().clone() for k, v in CILP_model.state_dict().items()},\n",
    "                \"optimizer_state_dict\": copy.deepcopy(optimizer.state_dict()),\n",
    "            }\n",
    "            print(f\"New best at epoch {epoch}: {best_val:.6f}\")\n",
    "\n",
    "    # Save best checkpoint\n",
    "    save_path = \"CILP_best.pt\"\n",
    "    torch.save(best_ckpt, save_path)\n",
    "    print(f\"Saved best checkpoint from epoch {best_epoch} to {save_path} (val={best_val:.6f})\")\n",
    "\n",
    "    # Optional: upload checkpoint to W&B as artifact\n",
    "    artifact = wandb.Artifact(\"CILP_best\", type=\"model\")\n",
    "    artifact.add_file(save_path)\n",
    "    run.log_artifact(artifact)\n",
    "\n",
    "    run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1936acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4046535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "projector = nn.Sequential(\n",
    "    nn.Linear(CILP_EMB_SIZE, 1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, 3200)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95ec9c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector = nn.Sequential(\n",
    "    nn.Linear(200, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 3200),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14e6727d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (embedder): Sequential(\n",
       "    (0): Conv2d(1, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(50, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(100, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=3200, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.assesment_utils import Classifier\n",
    "\n",
    "lidar_cnn = Classifier(1).to(device)\n",
    "lidar_cnn.load_state_dict(torch.load(\"../lidar_cnn.pt\", weights_only=True, map_location=torch.device('cpu')))\n",
    "# Do not unfreeze. Otherwise, it would be difficult to pass the assessment.\n",
    "for param in lidar_cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "lidar_cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f533275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projector_loss(model, batch):\n",
    "    rbg_img = batch[0].to(device)\n",
    "    lidar_depth = batch[2].to(device)\n",
    "    class_idx = batch[3].to(device)\n",
    "\n",
    "    # rbg_img, lidar_depth, class_idx = batch\n",
    "    imb_embs = CILP_model.img_embedder(rbg_img)\n",
    "    lidar_emb = lidar_cnn.get_embs(lidar_depth)\n",
    "    pred_lidar_embs = model(imb_embs)\n",
    "    return nn.MSELoss()(pred_lidar_embs, lidar_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(projector.parameters(), lr=3e-4, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.assesment_utils import print_loss\n",
    "# def train_model(model, optimizer, loss_func, epochs, train_dataloader, valid_dataloader):\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         train_loss = 0\n",
    "#         for step, batch in enumerate(train_dataloader):\n",
    "#             optimizer.zero_grad()\n",
    "#             loss = loss_func(model, batch)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             train_loss += loss.item()\n",
    "\n",
    "#         train_loss = train_loss / (step + 1)\n",
    "#         print_loss(epoch, train_loss, is_train=True)\n",
    "        \n",
    "#         model.eval()\n",
    "#         valid_loss = 0\n",
    "#         for step, batch in enumerate(valid_dataloader):\n",
    "#             loss = loss_func(model, batch)\n",
    "#             valid_loss += loss.item()\n",
    "#         valid_loss = valid_loss / (step + 1)\n",
    "#         print_loss(epoch, valid_loss, is_train=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b831e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch   0 | Train Loss: 5.4660\n",
      "Epoch   0 | Valid Loss: 4.7688\n",
      "Epoch   1 | Train Loss: 4.7992\n",
      "Epoch   1 | Valid Loss: 4.5415\n",
      "Epoch   2 | Train Loss: 4.5046\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch   2 | Valid Loss: 4.1923\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch   3 | Train Loss: 3.9888\n",
      "Epoch   3 | Valid Loss: 3.6321\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch   4 | Train Loss: 3.5619\n",
      "Epoch   4 | Valid Loss: 3.3747\n",
      "Epoch   5 | Train Loss: 3.3923\n",
      "Epoch   5 | Valid Loss: 3.3372\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch   6 | Train Loss: 3.2529\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch   6 | Valid Loss: 3.2315\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch   7 | Train Loss: 3.1921\n",
      "Epoch   7 | Valid Loss: 3.1760\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch   8 | Train Loss: 3.0971\n",
      "Epoch   8 | Valid Loss: 3.0997\n",
      "Epoch   9 | Train Loss: 3.0578\n",
      "Epoch   9 | Valid Loss: 3.0186\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  10 | Train Loss: 2.9911\n",
      "Epoch  10 | Valid Loss: 3.0224\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  11 | Train Loss: 2.9280\n",
      "Epoch  11 | Valid Loss: 2.9065\n",
      "Epoch  12 | Train Loss: 2.9068\n",
      "Epoch  12 | Valid Loss: 2.8760\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  13 | Train Loss: 2.8554\n",
      "Epoch  13 | Valid Loss: 2.7640\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  14 | Train Loss: 2.7954\n",
      "Epoch  14 | Valid Loss: 2.7983\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  15 | Train Loss: 2.7611\n",
      "Epoch  15 | Valid Loss: 2.7773\n",
      "Epoch  16 | Train Loss: 2.7097\n",
      "Epoch  16 | Valid Loss: 2.7092\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  17 | Train Loss: 2.6559\n",
      "Epoch  17 | Valid Loss: 2.6913\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  18 | Train Loss: 2.6301\n",
      "Epoch  18 | Valid Loss: 2.6492\n",
      "Epoch  19 | Train Loss: 2.5775\n",
      "Epoch  19 | Valid Loss: 2.6158\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  20 | Train Loss: 2.5580\n",
      "Epoch  20 | Valid Loss: 2.5877\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  21 | Train Loss: 2.5155\n",
      "Epoch  21 | Valid Loss: 2.5106\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  22 | Train Loss: 2.4955\n",
      "Epoch  22 | Valid Loss: 2.5111\n",
      "Epoch  23 | Train Loss: 2.4543\n",
      "Epoch  23 | Valid Loss: 2.4419\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  24 | Train Loss: 2.4191\n",
      "Epoch  24 | Valid Loss: 2.4512\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  25 | Train Loss: 2.3974\n",
      "Epoch  25 | Valid Loss: 2.4218\n",
      "Epoch  26 | Train Loss: 2.3653\n",
      "Epoch  26 | Valid Loss: 2.3909\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  27 | Train Loss: 2.3173\n",
      "Epoch  27 | Valid Loss: 2.3279\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  28 | Train Loss: 2.3109\n",
      "Epoch  28 | Valid Loss: 2.3420\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  29 | Train Loss: 2.2821\n",
      "Epoch  29 | Valid Loss: 2.2972\n",
      "Epoch  30 | Train Loss: 2.2706\n",
      "Epoch  30 | Valid Loss: 2.3098\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  31 | Train Loss: 2.2661\n",
      "Epoch  31 | Valid Loss: 2.2398\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  32 | Train Loss: 2.2209\n",
      "Epoch  32 | Valid Loss: 2.2485\n",
      "Epoch  33 | Train Loss: 2.2131\n",
      "Epoch  33 | Valid Loss: 2.2315\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  34 | Train Loss: 2.2115\n",
      "Epoch  34 | Valid Loss: 2.2604\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  35 | Train Loss: 2.1841\n",
      "Epoch  35 | Valid Loss: 2.2191\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  36 | Train Loss: 2.1620\n",
      "Epoch  36 | Valid Loss: 2.2060\n",
      "Epoch  37 | Train Loss: 2.1249\n",
      "Epoch  37 | Valid Loss: 2.1845\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  38 | Train Loss: 2.1359\n",
      "Epoch  38 | Valid Loss: 2.2127\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  39 | Train Loss: 2.0987\n",
      "Epoch  39 | Valid Loss: 2.1957\n",
      "Epoch  40 | Train Loss: 2.1030\n",
      "Epoch  40 | Valid Loss: 2.1461\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  41 | Train Loss: 2.0901\n",
      "Epoch  41 | Valid Loss: 2.1537\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  42 | Train Loss: 2.0691\n",
      "Epoch  42 | Valid Loss: 2.1452\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  43 | Train Loss: 2.0585\n",
      "Epoch  43 | Valid Loss: 2.1176\n",
      "Epoch  44 | Train Loss: 2.0628\n",
      "Epoch  44 | Valid Loss: 2.1361\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  45 | Train Loss: 2.0422\n",
      "Epoch  45 | Valid Loss: 2.0375\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  46 | Train Loss: 2.0282\n",
      "Epoch  46 | Valid Loss: 2.0589\n",
      "Epoch  47 | Train Loss: 2.0195\n",
      "Epoch  47 | Valid Loss: 2.0910\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  48 | Train Loss: 2.0097\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  48 | Valid Loss: 2.0784\n",
      "Epoch  49 | Train Loss: 2.0011\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  49 | Valid Loss: 2.0663\n",
      "Epoch  50 | Train Loss: 1.9871\n",
      "Epoch  50 | Valid Loss: 2.0815\n",
      "Epoch  51 | Train Loss: 1.9691\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  51 | Valid Loss: 2.0610\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  52 | Train Loss: 1.9526\n",
      "Epoch  52 | Valid Loss: 2.0763\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  53 | Train Loss: 1.9566\n",
      "Epoch  53 | Valid Loss: 2.0166\n",
      "Epoch  54 | Train Loss: 1.9514\n",
      "Epoch  54 | Valid Loss: 2.0576\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  55 | Train Loss: 1.9327\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  55 | Valid Loss: 2.0201\n",
      "Epoch  56 | Train Loss: 1.9103\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  56 | Valid Loss: 2.0086\n",
      "Epoch  57 | Train Loss: 1.9195\n",
      "Epoch  57 | Valid Loss: 2.0306\n",
      "Epoch  58 | Train Loss: 1.9132\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  58 | Valid Loss: 2.0535\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  59 | Train Loss: 1.9186\n",
      "Epoch  59 | Valid Loss: 2.0586\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  60 | Train Loss: 1.9010\n",
      "Epoch  60 | Valid Loss: 2.0197\n",
      "Epoch  61 | Train Loss: 1.8876\n",
      "Epoch  61 | Valid Loss: 2.0145\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  62 | Train Loss: 1.8802\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  62 | Valid Loss: 2.0501\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  63 | Train Loss: 1.8722\n",
      "Epoch  63 | Valid Loss: 2.0173\n",
      "Epoch  64 | Train Loss: 1.8658\n",
      "Epoch  64 | Valid Loss: 1.9837\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  65 | Train Loss: 1.8414\n",
      "Epoch  65 | Valid Loss: 1.9566\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  66 | Train Loss: 1.8640\n",
      "Epoch  66 | Valid Loss: 2.0163\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  67 | Train Loss: 1.8470\n",
      "Epoch  67 | Valid Loss: 1.9783\n",
      "Epoch  68 | Train Loss: 1.8317\n",
      "Epoch  68 | Valid Loss: 1.9861\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Epoch  69 | Train Loss: 1.8200\n",
      "Epoch  69 | Valid Loss: 1.9974\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01massesment_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_model \u001b[38;5;28;01mas\u001b[39;00m train_model_assessment\n\u001b[32m      7\u001b[39m epochs = \u001b[32m100\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtrain_model_assessment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprojector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_projector_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/assessment2/src/assesment_utils.py:62\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, optimizer, loss_func, epochs, train_dataloader, valid_dataloader)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[32m     61\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     loss = \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     loss.backward()\n\u001b[32m     64\u001b[39m     optimizer.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mget_projector_loss\u001b[39m\u001b[34m(model, batch)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# rbg_img, lidar_depth, class_idx = batch\u001b[39;00m\n\u001b[32m      7\u001b[39m imb_embs = CILP_model.img_embedder(rbg_img)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m lidar_emb = \u001b[43mlidar_cnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_embs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlidar_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m pred_lidar_embs = model(imb_embs)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nn.MSELoss()(pred_lidar_embs, lidar_emb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/assessment2/src/assesment_utils.py:32\u001b[39m, in \u001b[36mClassifier.get_embs\u001b[39m\u001b[34m(self, imgs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embs\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgs):\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/compv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/compv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/compv/lib/python3.11/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/compv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/compv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/compv/lib/python3.11/site-packages/torch/nn/modules/pooling.py:224\u001b[39m, in \u001b[36mMaxPool2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/compv/lib/python3.11/site-packages/torch/_jit_internal.py:627\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/compv/lib/python3.11/site-packages/torch/nn/functional.py:827\u001b[39m, in \u001b[36m_max_pool2d\u001b[39m\u001b[34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[39m\n\u001b[32m    825\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    826\u001b[39m     stride = torch.jit.annotate(\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in CILP_model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in lidar_cnn.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "from src.assesment_utils import train_model as train_model_assessment\n",
    "epochs = 100\n",
    "\n",
    "train_model_assessment(projector, optimizer, get_projector_loss, epochs, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd495570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB mean/std/norm: -0.00023113441420719028 0.07071582227945328 1.0\n",
      "LiDAR mean/std/norm: 0.32104167342185974 2.2003915309906006 109.63412475585938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    rgb = batch[0].to(device)\n",
    "    lidar = batch[2].to(device)\n",
    "    e_rgb = CILP_model.img_embedder(rgb)\n",
    "    e_lid = lidar_cnn.get_embs(lidar)\n",
    "\n",
    "print(\"RGB mean/std/norm:\", e_rgb.mean().item(), e_rgb.std().item(), e_rgb.norm(dim=1).mean().item())\n",
    "print(\"LiDAR mean/std/norm:\", e_lid.mean().item(), e_lid.std().item(), e_lid.norm(dim=1).mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ed286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.278610944747925\n",
      "50 2.4535748958587646\n",
      "100 2.0725209712982178\n",
      "150 1.7902824878692627\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "200 1.55489182472229\n",
      "250 1.3500958681106567\n",
      "300 1.1765564680099487\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "350 1.025274395942688\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "400 0.891940176486969\n",
      "450 0.7780547142028809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "projector.train()\n",
    "batch = next(iter(train_dataloader))\n",
    "for i in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    loss = get_projector_loss(projector, batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 50 == 0:\n",
    "        print(i, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d91246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
